{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matplotlib.rcParams['savefig.dpi'] = 144\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection Lab: Incorporating Weather Data\n",
    "\n",
    "In this lab, we go ahead and add weather data to our already-well-performing model. It seems reasonable to assume that weather affects the usage of the CitiBike system. The `weatherdata/nycp.csv` file contains daily National Weather Service records for Central Park. Add features from these records to your model.\n",
    "\n",
    "The code here is essentially copy-and-pasted from the `anomaly2.ipynb` notebook, and includes the feature extraction pipelines for both our time-based features and our historical count features. \n",
    "\n",
    "Your task is the following\n",
    "1. Engineer a new feature (or features) for the day's average temperature (as reported at Central Park).\n",
    "2. Combine the time-based, historical, and (your new) weather-based features into a FeatureUnion\n",
    "3. Fit a linear regression model and evaluate what the performance improvement is over our previous best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn import base\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "def load_counts(fn):\n",
    "    zf = zipfile.ZipFile(fn, 'r')\n",
    "    df = pd.read_csv(zf.open(zf.namelist()[0]))\n",
    "    counts = df['starttime'].str.split(' ', 1).apply(lambda x: x[0]).value_counts()\n",
    "    if '-' in counts.index[0]:\n",
    "        counts.index = pd.to_datetime(counts.index, format='%Y-%m-%d')\n",
    "    else:\n",
    "        counts.index = pd.to_datetime(counts.index, format='%m/%d/%Y')\n",
    "    return counts.sort_index()\n",
    "\n",
    "fns = glob.glob('tripdata/[0-9][0-9][0-9][0-9][0-9][0-9]-citibike-tripdata.zip')\n",
    "counts = pd.concat([load_counts(fn) for fn in sorted(fns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FourierComponents(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self, period):\n",
    "        self.period = period\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.X0 = X[0]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        dt = (X - self.X0).days * 2 * np.pi / self.period\n",
    "        return np.c_[np.sin(dt), np.cos(dt)]\n",
    "\n",
    "class DayofWeek(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def day_vector(self, day):\n",
    "        v = np.zeros(7)\n",
    "        v[day] = 1\n",
    "        return v\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.stack(self.day_vector(d) for d in X.dayofweek)\n",
    "\n",
    "class QuadBackground(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.X0 = X[0]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        days = (X - self.X0).days\n",
    "        return np.c_[days, days**2]\n",
    "    \n",
    "class ColumnExtractor(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.cols]\n",
    "    \n",
    "class IndexExtractor(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "union = FeatureUnion([('date', QuadBackground()),\n",
    "                      ('fourier-y', FourierComponents(365)),\n",
    "                      ('fourier-2', FourierComponents(365/2.)),\n",
    "                      ('fourier-m', FourierComponents(365/12.)),\n",
    "                      ('fourier-8', FourierComponents(365/8.)),\n",
    "                      ('dayofweek', DayofWeek()),])\n",
    "time_pipe = Pipeline([('index', IndexExtractor()),\n",
    "                      ('features', union)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_df = pd.DataFrame({'counts': counts, 'previous': counts.shift(1).fillna(method='bfill'),\n",
    "                          'rolling': counts.rolling(window=5).mean().shift(1).fillna(method='bfill')})\n",
    "\n",
    "hist_pipe = Pipeline([('previous', ColumnExtractor(['previous', 'rolling']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Weather Data\n",
    "Here's the dataset of weather. We added in a column with the dates already parsed for you. Explore it to determine which columns actually track temperature on a given day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"weatherdata/nycp.csv\")\n",
    "#here, we'll even give you a nice datetime object to work with\n",
    "weather[\"DT\"] = pd.to_datetime(weather[\"DATE\"].apply(str), format=\"%Y%m%d\")\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What now?\n",
    "\n",
    "Some hints:\n",
    "- The first thing you'll need to do is line up the dates in the `weather` dataframe with the `counts_df` dataframe (i.e. join the two tables).\n",
    "- You can use the `ColumnExtractor` transformer we've already written to pull out temperature as a feature\n",
    "- From there, set up a `FeatureUnion` (combining the pipelines already here with your new feature extraction)\n",
    "- Last but not least, train a Linear Regression model and compute the RMSE. How did it do?\n",
    "\n",
    "Once you've gotten that all done, a fun one: how much does ridership increase for every degree Fahrenheit? (Hint: The coefficients of the linear model are stored in the .coef_ attribute of a LinearRegression object.)\n",
    "\n",
    "Next steps: There are a few other interesting columns in this dataset. Add those into the regression as well to see how they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
